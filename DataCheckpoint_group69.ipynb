{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**If you lost points on the last checkpoint you can get them back by responding to TA/IA feedback**  \n",
    "\n",
    "Update/change the relevant sections where you lost those points, make sure you respond on GitHub Issues to your TA/IA to call their attention to the changes you made here.\n",
    "\n",
    "Please update your Timeline... no battle plan survives contact with the enemy, so make sure we understand how your plans have changed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COGS 108 - Data Checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Names\n",
    "\n",
    "- Vishaal Gaddipati\n",
    "- Ryan Chen\n",
    "- Georolyn Ngo\n",
    "- Thanh Trinh\n",
    "- Armaan Shaikh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Research Question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the correlation between the average temperature of a given state and the quantity of Division I NCAA basketball players generated between season 2018-2019 and 2023-2024? Furthermore, how does the average temperature per state relate to the skill level of Division I basketball players, as indicated by the average of points, rebounds, and assists over the season, within that same timeframe?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background and Prior Work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The debate over which state produces the best basketball players has long been a point of contention among Americans, with popular contenders including New York, California, and Florida. While previous research has attempted to answer this question, it has only focused on the socio-economic factors, such as the study by James Tompsett and Chris Knoester that focused extensively on the likelihood of high school athletes advancing to collegiate levels.<a name=\"cite_ref_1\"/>[<sup>1</sup>](#cite_note_1) Indicators of family socioeconomic statuses, athletic development and merit, academic expectations and knowledge, and school contexts were used to predict the likelihood of becoming a college athlete. It was shown that high school athletes with a stronger socioeconomic background are much more likely to become collegiate athletes. The correlation with this is clear but it still does not answer our question. Thus, we aim to investigate another less conventional variable that could help us identify the best basketball state - the average temperature of the state.\n",
    "\n",
    "There have been studies in the past that have looked at the effect of environmental factors on active participation in physical activities. The paper titled \"Assessing the Effects of Weather Conditions on Physical Activity Participation Using Objective Measures\" by Catherine B. Chan and Daniel A. Ryan examines how different weather conditions influence physical activity levels.<a name=\"cite_ref_2\"/>[<sup>2</sup>](#cite_note_2) The study identifies weather as a significant barrier to physical activity, particularly focusing on how adverse conditions such as low temperatures, rain, and snow decrease participation. Using data from various demographic groups, the study highlights that physical activity levels are generally higher on warmer days and lower during inclement weather. We intend on extending this study into the context of basketball. Further, a study done by David Hancock, Matthew Vierimaa, and Ashley Newman revealed that communities with populations of 250,000-499,999 are talent hotspots for high-level competitive basketball. They explained that this is due to favorable infrastructure and social structure, but call for more research into other factors such as crime rates and green spaces. <a name=\"cite_ref_3\"/>[<sup>3</sup>](#cite_note_3)\n",
    "\n",
    "We aim to examine the correlation between a state's average temperature and the number of Division I NCAA basketball players it generates between 2019 and 2024 and foresee that environmental factors such as average temperature would provide residents in those areas different, unequal opportunities for physical activity. Another factor that could come into play is sports culture. As sports are strongly integrated in cultures, we may also observe a change in the popularity of different sports due to weather and how accessible that sport is. The accessibility of a sport due to climate could potentially have an effect on the opportunities for training and skill development, further impacting on court performance down the line. Investigating how average temperatures in different states correlate with the emergence of Division I basketball players can offer valuable insights into the broader determinants of athletic success. \n",
    "\n",
    "<a name=\"cite_note_1\"/> [1](#cite_ref_1) Tompsett, J., & Knoester, C. (2022). The Making of a College Athlete: High School Experiences, Socioeconomic Advantages, and the Likelihood of Playing College Sports. Sociology of Sport Journal, 39(2), 129–140. https://doi.org/10.1123/ssj.2020-0142\n",
    "\n",
    "<a name=\"cite_note_2\"/> [2](#cite_ref_2) Chan, C. B., & Ryan, D. A. (2009). Assessing the effects of weather conditions on physical activity participation using objective measures. International journal of environmental research and public health, 6(10), 2639–2654. https://doi.org/10.3390/ijerph6102639\n",
    "\n",
    "<a name=\"cite_note_3\"/> [3](#cite_ref_3) Hancock, D. J., Vierimaa, M., & Newman, A. (2022). The geography of talent development. Frontiers in sports and active living, 4, 1031227. https://doi.org/10.3389/fspor.2022.1031227"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypothesis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We hypothesize that there will be a positive correlation between the average temperature of a state and the quantity of Division I NCAA basketball players generated between 2018 and 2023. Our rationale is that warmer climates may facilitate greater participation in outdoor sports activities, including basketball, thereby potentially leading to an increased number of talented athletes pursuing collegiate basketball opportunities.\n",
    "\n",
    "Additionally, we anticipate that states with higher average temperatures will exhibit a positive correlation with the skill level of Division I basketball players. Specifically, we expect that players hailing from states with warmer climates will demonstrate a higher combined average of points, rebounds, and assists over the season. This hypothesis is grounded in the notion that favorable weather conditions may provide athletes with more opportunities for training and skill development, ultimately enhancing their performance on the court."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data overview\n",
    "\n",
    "(Datasets #2 and #3 required some web scraping) \n",
    "- Dataset #1\n",
    "  - Dataset Name: Average Temperature by State\n",
    "  - Link to the dataset: https://www.ncei.noaa.gov/access/monitoring/climate-at-a-glance/statewide/time-series/1/tavg/1/3/1895-2024?base_prd=true&begbaseyear=1901&endbaseyear=2000\n",
    "  - Number of observations: 163527\n",
    "  - Number of variables: 4\n",
    "- Dataset #2\n",
    "  - Dataset Name:\n",
    "  - Link to the dataset: https://basketball.realgm.com/ncaa/players/2024/\n",
    "  - Number of observations:\n",
    "  - Number of variables:\n",
    "- Dataset #3\n",
    "  - Dataset Name: \n",
    "  - Link to the dataset: https://stats.ncaa.org/rankings/change_sport_year_div\n",
    "  - Number of observations:\n",
    "  - Number of variables:\n",
    "\n",
    "Now write 2 - 5 sentences describing each dataset here. Include a short description of the important variables in the dataset; what the metrics and datatypes are, what concepts they may be proxies for. Include information about how you would need to wrangle/clean/preprocess the dataset\n",
    "- Dataset #1: This dataset covers average temperature by state measured in Fahrenheit from 1895 to 2024 on a monthly basis. It uses a unique code specified in the documentation found on their page that signifies key factors such as the state and year in consideration. The key variables in the dataset are the state, year, month, and temperature all of which are read as type object. All 50 states are included, the years span from 1895-2024, covering all 12 months, with the temperature on the Fahrenheit scale. This dataset is crucial as we will be able to extrapolate the yearly temperature average for each state from 2018-2023 via data wrangling/cleaning. This would involve using a dictionary to interpret the state codes, dropping the years we are not analyzing, and creating a column for the mean temperature over all 12 months. This can then be used to analyze the role the temperature plays in relation to our research question.\n",
    "- Dataset #2:\n",
    "- Dataset #3:\n",
    "\n",
    "If you plan to use multiple datasets, add a few sentences about how you plan to combine these datasets.\n",
    "\n",
    "We plan to combine these datasets by... [FILL IN]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset #1: Average Temperature By State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "163527"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The data cleaning will require converting some of the conventions used by the organization into equivalents. Ex: 001 at the beginning of a code indicated Alabama.\n",
    "weather_df = pd.read_csv('https://www.ncei.noaa.gov/pub/data/cirs/climdiv/climdiv-tmpcst-v1.0.0-20240506', delim_whitespace=True, dtype=str) \n",
    "weather_df.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code is an indicator based on a sequential standard found in detail here: https://www.ncei.noaa.gov/pub/data/cirs/climdiv/state-readme.txt\n",
    "weather_df.columns = [\"code\", \"January\", \"February\", \"March\", \"April\", \"May\", \"June\", \"July\", \"August\", \"September\", \"October\", \"November\", \"December\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary for state code mappings\n",
    "state_codes = {\n",
    "    '001': 'Alabama',\n",
    "    '002': 'Arizona',\n",
    "    '003': 'Arkansas',\n",
    "    '004': 'California',\n",
    "    '005': 'Colorado',\n",
    "    '006': 'Connecticut',\n",
    "    '007': 'Delaware',\n",
    "    '008': 'Florida',\n",
    "    '009': 'Georgia',\n",
    "    '010': 'Idaho',\n",
    "    '011': 'Illinois',\n",
    "    '012': 'Indiana',\n",
    "    '013': 'Iowa',\n",
    "    '014': 'Kansas',\n",
    "    '015': 'Kentucky',\n",
    "    '016': 'Louisiana',\n",
    "    '017': 'Maine',\n",
    "    '018': 'Maryland',\n",
    "    '019': 'Massachusetts',\n",
    "    '020': 'Michigan',\n",
    "    '021': 'Minnesota',\n",
    "    '022': 'Mississippi',\n",
    "    '023': 'Missouri',\n",
    "    '024': 'Montana',\n",
    "    '025': 'Nebraska',\n",
    "    '026': 'Nevada',\n",
    "    '027': 'New Hampshire',\n",
    "    '028': 'New Jersey',\n",
    "    '029': 'New Mexico',\n",
    "    '030': 'New York',\n",
    "    '031': 'North Carolina',\n",
    "    '032': 'North Dakota',\n",
    "    '033': 'Ohio',\n",
    "    '034': 'Oklahoma',\n",
    "    '035': 'Oregon',\n",
    "    '036': 'Pennsylvania',\n",
    "    '037': 'Rhode Island',\n",
    "    '038': 'South Carolina',\n",
    "    '039': 'South Dakota',\n",
    "    '040': 'Tennessee',\n",
    "    '041': 'Texas',\n",
    "    '042': 'Utah',\n",
    "    '043': 'Vermont',\n",
    "    '044': 'Virginia',\n",
    "    '045': 'Washington',\n",
    "    '046': 'West Virginia',\n",
    "    '047': 'Wisconsin',\n",
    "    '048': 'Wyoming',\n",
    "    '050': 'Alaska'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove data points not from 2018 to 2023\n",
    "weather_df = weather_df[weather_df[\"code\"].str[6:].isin([\"2018\", \"2019\", \"2020\", \"2021\", \"2022\", \"2023\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove codes not from 001 to 050, as we are only analyzing the 50 states \n",
    "weather_df = weather_df[weather_df[\"code\"].str[0:3].isin(state_codes.keys())].reset_index().drop([\"index\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 2 new columns to represent the year and the state of a 12-month average temperature period\n",
    "weather_df.insert(1, \"year\", weather_df[\"code\"].str[6:], True)\n",
    "weather_df.insert(1, \"state\", weather_df[\"code\"].str[0:3],True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert state codes into their state name strings\n",
    "weather_df[\"state\"] = weather_df[\"state\"].map(state_codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop code as it is no longer needed for data analyzing\n",
    "weather_df = weather_df.drop([\"code\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for any missing data\n",
    "weather_df.isna().any().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "state        object\n",
       "year         object\n",
       "January      object\n",
       "February     object\n",
       "March        object\n",
       "April        object\n",
       "May          object\n",
       "June         object\n",
       "July         object\n",
       "August       object\n",
       "September    object\n",
       "October      object\n",
       "November     object\n",
       "December     object\n",
       "dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>year</th>\n",
       "      <th>January</th>\n",
       "      <th>February</th>\n",
       "      <th>March</th>\n",
       "      <th>April</th>\n",
       "      <th>May</th>\n",
       "      <th>June</th>\n",
       "      <th>July</th>\n",
       "      <th>August</th>\n",
       "      <th>September</th>\n",
       "      <th>October</th>\n",
       "      <th>November</th>\n",
       "      <th>December</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>2018</td>\n",
       "      <td>40.40</td>\n",
       "      <td>58.00</td>\n",
       "      <td>55.40</td>\n",
       "      <td>59.50</td>\n",
       "      <td>74.40</td>\n",
       "      <td>79.30</td>\n",
       "      <td>80.70</td>\n",
       "      <td>79.50</td>\n",
       "      <td>79.40</td>\n",
       "      <td>67.40</td>\n",
       "      <td>50.40</td>\n",
       "      <td>49.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>2019</td>\n",
       "      <td>46.50</td>\n",
       "      <td>56.10</td>\n",
       "      <td>55.00</td>\n",
       "      <td>63.50</td>\n",
       "      <td>74.20</td>\n",
       "      <td>78.10</td>\n",
       "      <td>80.60</td>\n",
       "      <td>80.60</td>\n",
       "      <td>80.20</td>\n",
       "      <td>67.80</td>\n",
       "      <td>50.60</td>\n",
       "      <td>51.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>2020</td>\n",
       "      <td>49.50</td>\n",
       "      <td>51.00</td>\n",
       "      <td>63.50</td>\n",
       "      <td>62.00</td>\n",
       "      <td>68.90</td>\n",
       "      <td>76.90</td>\n",
       "      <td>80.90</td>\n",
       "      <td>80.20</td>\n",
       "      <td>74.30</td>\n",
       "      <td>66.90</td>\n",
       "      <td>58.40</td>\n",
       "      <td>45.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>2021</td>\n",
       "      <td>46.60</td>\n",
       "      <td>46.70</td>\n",
       "      <td>59.60</td>\n",
       "      <td>61.60</td>\n",
       "      <td>69.40</td>\n",
       "      <td>77.00</td>\n",
       "      <td>79.30</td>\n",
       "      <td>80.00</td>\n",
       "      <td>73.90</td>\n",
       "      <td>67.30</td>\n",
       "      <td>52.20</td>\n",
       "      <td>56.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>2022</td>\n",
       "      <td>43.90</td>\n",
       "      <td>50.10</td>\n",
       "      <td>57.40</td>\n",
       "      <td>62.60</td>\n",
       "      <td>73.50</td>\n",
       "      <td>80.40</td>\n",
       "      <td>81.70</td>\n",
       "      <td>79.30</td>\n",
       "      <td>73.70</td>\n",
       "      <td>61.20</td>\n",
       "      <td>55.30</td>\n",
       "      <td>49.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>2019</td>\n",
       "      <td>7.50</td>\n",
       "      <td>15.50</td>\n",
       "      <td>26.50</td>\n",
       "      <td>28.50</td>\n",
       "      <td>43.00</td>\n",
       "      <td>54.00</td>\n",
       "      <td>58.10</td>\n",
       "      <td>51.50</td>\n",
       "      <td>44.40</td>\n",
       "      <td>30.80</td>\n",
       "      <td>19.80</td>\n",
       "      <td>6.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>2020</td>\n",
       "      <td>-6.40</td>\n",
       "      <td>1.50</td>\n",
       "      <td>12.00</td>\n",
       "      <td>27.50</td>\n",
       "      <td>43.30</td>\n",
       "      <td>50.50</td>\n",
       "      <td>53.20</td>\n",
       "      <td>52.10</td>\n",
       "      <td>42.00</td>\n",
       "      <td>28.90</td>\n",
       "      <td>14.50</td>\n",
       "      <td>10.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>2021</td>\n",
       "      <td>10.60</td>\n",
       "      <td>1.00</td>\n",
       "      <td>9.10</td>\n",
       "      <td>23.90</td>\n",
       "      <td>40.30</td>\n",
       "      <td>50.90</td>\n",
       "      <td>53.90</td>\n",
       "      <td>49.40</td>\n",
       "      <td>39.40</td>\n",
       "      <td>27.90</td>\n",
       "      <td>4.60</td>\n",
       "      <td>6.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>2022</td>\n",
       "      <td>2.60</td>\n",
       "      <td>8.20</td>\n",
       "      <td>16.70</td>\n",
       "      <td>24.90</td>\n",
       "      <td>40.10</td>\n",
       "      <td>52.70</td>\n",
       "      <td>53.30</td>\n",
       "      <td>50.10</td>\n",
       "      <td>42.70</td>\n",
       "      <td>28.80</td>\n",
       "      <td>16.30</td>\n",
       "      <td>7.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>2023</td>\n",
       "      <td>11.00</td>\n",
       "      <td>6.00</td>\n",
       "      <td>13.50</td>\n",
       "      <td>16.70</td>\n",
       "      <td>39.80</td>\n",
       "      <td>49.90</td>\n",
       "      <td>56.10</td>\n",
       "      <td>53.30</td>\n",
       "      <td>40.80</td>\n",
       "      <td>27.80</td>\n",
       "      <td>20.40</td>\n",
       "      <td>5.90</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>294 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       state  year January February  March  April    May   June   July August  \\\n",
       "0    Alabama  2018   40.40    58.00  55.40  59.50  74.40  79.30  80.70  79.50   \n",
       "1    Alabama  2019   46.50    56.10  55.00  63.50  74.20  78.10  80.60  80.60   \n",
       "2    Alabama  2020   49.50    51.00  63.50  62.00  68.90  76.90  80.90  80.20   \n",
       "3    Alabama  2021   46.60    46.70  59.60  61.60  69.40  77.00  79.30  80.00   \n",
       "4    Alabama  2022   43.90    50.10  57.40  62.60  73.50  80.40  81.70  79.30   \n",
       "..       ...   ...     ...      ...    ...    ...    ...    ...    ...    ...   \n",
       "289   Alaska  2019    7.50    15.50  26.50  28.50  43.00  54.00  58.10  51.50   \n",
       "290   Alaska  2020   -6.40     1.50  12.00  27.50  43.30  50.50  53.20  52.10   \n",
       "291   Alaska  2021   10.60     1.00   9.10  23.90  40.30  50.90  53.90  49.40   \n",
       "292   Alaska  2022    2.60     8.20  16.70  24.90  40.10  52.70  53.30  50.10   \n",
       "293   Alaska  2023   11.00     6.00  13.50  16.70  39.80  49.90  56.10  53.30   \n",
       "\n",
       "    September October November December  \n",
       "0       79.40   67.40    50.40    49.00  \n",
       "1       80.20   67.80    50.60    51.30  \n",
       "2       74.30   66.90    58.40    45.90  \n",
       "3       73.90   67.30    52.20    56.80  \n",
       "4       73.70   61.20    55.30    49.10  \n",
       "..        ...     ...      ...      ...  \n",
       "289     44.40   30.80    19.80     6.70  \n",
       "290     42.00   28.90    14.50    10.60  \n",
       "291     39.40   27.90     4.60     6.80  \n",
       "292     42.70   28.80    16.30     7.10  \n",
       "293     40.80   27.80    20.40     5.90  \n",
       "\n",
       "[294 rows x 14 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>year</th>\n",
       "      <th>January</th>\n",
       "      <th>February</th>\n",
       "      <th>March</th>\n",
       "      <th>April</th>\n",
       "      <th>May</th>\n",
       "      <th>June</th>\n",
       "      <th>July</th>\n",
       "      <th>August</th>\n",
       "      <th>September</th>\n",
       "      <th>October</th>\n",
       "      <th>November</th>\n",
       "      <th>December</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>California</td>\n",
       "      <td>2023</td>\n",
       "      <td>42.60</td>\n",
       "      <td>42.70</td>\n",
       "      <td>44.10</td>\n",
       "      <td>55.30</td>\n",
       "      <td>61.90</td>\n",
       "      <td>66.70</td>\n",
       "      <td>78.90</td>\n",
       "      <td>75.80</td>\n",
       "      <td>68.00</td>\n",
       "      <td>62.20</td>\n",
       "      <td>51.90</td>\n",
       "      <td>48.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         state  year January February  March  April    May   June   July  \\\n",
       "23  California  2023   42.60    42.70  44.10  55.30  61.90  66.70  78.90   \n",
       "\n",
       "   August September October November December  \n",
       "23  75.80     68.00   62.20    51.90    48.00  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test to get the California 12 month average temperature in 2023\n",
    "weather_df[(weather_df['state'] == 'California') & (weather_df['year'] == '2023')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert month columns to floats\n",
    "weather_df.iloc[:, 2:] = weather_df.iloc[:, 2:].astype(float)\n",
    "\n",
    "# Calculate the average of each row\n",
    "weather_df['average_temperature'] = weather_df.iloc[:, 2:].mean(axis=1)\n",
    "\n",
    "# Drop the January to December columns\n",
    "weather_df.drop(weather_df.columns[2:-1], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>year</th>\n",
       "      <th>average_temperature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>2018</td>\n",
       "      <td>64.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>2019</td>\n",
       "      <td>65.375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>2020</td>\n",
       "      <td>64.866667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>2021</td>\n",
       "      <td>64.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>2022</td>\n",
       "      <td>64.016667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>2019</td>\n",
       "      <td>32.191667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>2020</td>\n",
       "      <td>27.475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>2021</td>\n",
       "      <td>26.483333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>2022</td>\n",
       "      <td>28.625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>2023</td>\n",
       "      <td>28.433333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>294 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       state  year average_temperature\n",
       "0    Alabama  2018               64.45\n",
       "1    Alabama  2019              65.375\n",
       "2    Alabama  2020           64.866667\n",
       "3    Alabama  2021                64.2\n",
       "4    Alabama  2022           64.016667\n",
       "..       ...   ...                 ...\n",
       "289   Alaska  2019           32.191667\n",
       "290   Alaska  2020              27.475\n",
       "291   Alaska  2021           26.483333\n",
       "292   Alaska  2022              28.625\n",
       "293   Alaska  2023           28.433333\n",
       "\n",
       "[294 rows x 3 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>year</th>\n",
       "      <th>average_temperature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>California</td>\n",
       "      <td>2023</td>\n",
       "      <td>58.175</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         state  year average_temperature\n",
       "23  California  2023              58.175"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test to get the California 1 year average temperature in 2023\n",
    "weather_df[(weather_df['state'] == 'California') & (weather_df['year'] == '2023')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "state\n",
       "Alabama           6\n",
       "Nevada            6\n",
       "New Jersey        6\n",
       "New Mexico        6\n",
       "New York          6\n",
       "North Carolina    6\n",
       "North Dakota      6\n",
       "Ohio              6\n",
       "Oklahoma          6\n",
       "Oregon            6\n",
       "Pennsylvania      6\n",
       "Rhode Island      6\n",
       "South Carolina    6\n",
       "South Dakota      6\n",
       "Tennessee         6\n",
       "Texas             6\n",
       "Utah              6\n",
       "Vermont           6\n",
       "Virginia          6\n",
       "Washington        6\n",
       "West Virginia     6\n",
       "Wisconsin         6\n",
       "Wyoming           6\n",
       "New Hampshire     6\n",
       "Nebraska          6\n",
       "Arizona           6\n",
       "Montana           6\n",
       "Arkansas          6\n",
       "California        6\n",
       "Colorado          6\n",
       "Connecticut       6\n",
       "Delaware          6\n",
       "Florida           6\n",
       "Georgia           6\n",
       "Idaho             6\n",
       "Illinois          6\n",
       "Indiana           6\n",
       "Iowa              6\n",
       "Kansas            6\n",
       "Kentucky          6\n",
       "Louisiana         6\n",
       "Maine             6\n",
       "Maryland          6\n",
       "Massachusetts     6\n",
       "Michigan          6\n",
       "Minnesota         6\n",
       "Mississippi       6\n",
       "Missouri          6\n",
       "Alaska            6\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hawaii is the state missing data\n",
    "weather_df['state'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset #2 (if you have more than one, use name instead of number here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## YOUR CODE TO LOAD/CLEAN/TIDY/WRANGLE THE DATA GOES HERE\n",
    "## FEEL FREE TO ADD MULTIPLE CELLS PER SECTION "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset #3 (if you have more than one, use name instead of number here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "## YOUR CODE TO LOAD/CLEAN/TIDY/WRANGLE THE DATA GOES HERE\n",
    "## FEEL FREE TO ADD MULTIPLE CELLS PER SECTION "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ethics & Privacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To identify biases or issues in the datasets, our group will conduct a comprehensive review of the data sources, including the list of Division 1 basketball players, their respective stats in different categories, and weather data from various sources such as Kaggle or NOAA. During this review, we will pay particular attention to any potential biases in the composition of the datasets, such as underrepresentation of certain demographic groups or regions, as well as any privacy concerns related to the inclusion of sensitive or potentially identifiable information.\n",
    "\n",
    "Our group will address these biases or issues by employing several strategies throughout the research process:\n",
    "\n",
    "Transparency: We will openly acknowledge any biases or limitations in the datasets, ensuring our analysis is conducted with full transparency and accountability. By providing clear documentation of our data sources, methodologies, and any assumptions made during the analysis, we will enable stakeholders to critically evaluate the findings and understand the context in which they were derived. We will scrutinize any potential biases in our datasets and methods, particularly socioeconomic biases that might influence or skew the analysis. We will make sure data accurately represent all demographics to prevent exclusion of lower-income populations. It is quite easy for machine learning algorithms to ignore the presence of bias in an attempt to uphold accuracy; however, if certain factors are ignored, the accuracy does not take a major hit and the predictions are not biased as well. Therefore, we attempt to fairly represent our dataset.\n",
    "\n",
    "Equity in Analysis: During analysis, we will keep in mind various relevant stakeholders of this project (such as athletes and colleges/universities) and address blindspots in our analysis through considering perspectives from different stakeholders. Further, we hold ourselves to a standard to not hold any biases while performing data analysis to prevent misuse of analytical strategies to propagate existing stereotypes or systemic biases. Our visualizations, summary statistics, and reports should include every point of valid data, and we will try our best to avoid dropping any points of data.\n",
    "\n",
    "Data Validation: We will validate the accuracy and integrity of the datasets through rigorous quality assurance measures, including data cleaning and verification procedures. This will involve checking for inconsistencies or errors, and implementing appropriate corrections to ensure the reliability of our analysis. We will consult multiple sources where possible to cross check obtained data and verify their correctness. Furthermore, we will validate our ability to utilize the data we have collected through checking column headers, data types, and null fields.\n",
    "\n",
    "Privacy Protection: We will prioritize safeguarding individuals privacy rights by adhering to relevant privacy regulations and guidelines, ensuring that any personally identifiable information is handled with care and only used in accordance with ethical standards. Visualizations, summary statistics, and reports should avoid private information where possible. One such way we will do so is by removing irrelevant personal information to our project such as the name, height, weight, and birth date of players in the datasets.\n",
    "\n",
    "By maintaining transparency in our methodology and being vigilant about ethical considerations, we aim to uphold the integrity of our research while contributing valuable insights into the socioeconomic factors affecting athletic opportunities in NCAA basketball.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Team Expectations "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* *Team Expectation 1*: Communicate in a timely manner with respect (via Discord or text group chat).\n",
    "* *Team Expectation 2*: Ensure the work completed is quality and meets all marks specified.\n",
    "* *Team Expectation 3*: Set deadlines for divided tasks and reach out whenever help is needed as early as possible.\n",
    "* *Team Expectation 4*: Actively partcipate in group meetings and varying aspects of the project.\n",
    "* *Team Expectation 5*: Keep track of current tasks and discussion points using meeting notes (via Google Docs)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Timeline Proposal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Meeting Date  | Meeting Time| Completed Before Meeting  | Discuss at Meeting |\n",
    "|---|---|---|---|\n",
    "| 4/25  |  11 AM | Read & Think about COGS 108 expectations; brainstorm topics/questions  | Determine best form of communication; Discuss and decide on final project topic; discuss hypothesis; begin background research | \n",
    "| 4/30  |  8 PM |  Do background research on topic | Discuss ideal dataset(s) and ethics; draft project proposal | \n",
    "| 5/3  | 8 PM  | Edit, finalize, and submit proposal; Search for datasets  | Discuss Wrangling and possible analytical approaches; Assign group members to lead each specific part   |\n",
    "| 5/12  | 12 PM  | Import & Wrangle Data (Ryan); EDA (Georolyn) | Review/Edit wrangling/EDA; Discuss Analysis Plan   |\n",
    "| 5/13  | 12 PM  | Finalize wrangling/EDA; Begin Analysis (Vishaal; Thanh) | Discuss/edit Analysis; Complete project check-in |\n",
    "| 5/20  | 12 PM  | Complete analysis; Draft results/conclusion/discussion (Armaan)| Discuss/edit full project |\n",
    "| 6/10  | Before 11:59 PM  | NA | Turn in Final Project & Group Project Surveys |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
